{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d5fccac-9671-452a-a6f7-0949a559b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe9413b-7981-4f9c-8ba9-af210a7c0121",
   "metadata": {},
   "source": [
    "## Downloading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "646a2848-72b5-4ac8-bd02-68da3e069e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.csv already exists in the current directory.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_chembl_id</th>\n",
       "      <th>IC50</th>\n",
       "      <th>units</th>\n",
       "      <th>smiles</th>\n",
       "      <th>pIC50</th>\n",
       "      <th>molecular_weight</th>\n",
       "      <th>n_hba</th>\n",
       "      <th>n_hbd</th>\n",
       "      <th>logp</th>\n",
       "      <th>ro5_fulfilled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL63786</td>\n",
       "      <td>3.000000e-03</td>\n",
       "      <td>nM</td>\n",
       "      <td>Brc1cccc(Nc2ncnc3cc4ccccc4cc23)c1</td>\n",
       "      <td>11.522879</td>\n",
       "      <td>349.021459</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5.28910</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL35820</td>\n",
       "      <td>6.000000e-03</td>\n",
       "      <td>nM</td>\n",
       "      <td>CCOc1cc2ncnc(Nc3cccc(Br)c3)c2cc1OCC</td>\n",
       "      <td>11.221849</td>\n",
       "      <td>387.058239</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.93330</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL53711</td>\n",
       "      <td>6.000000e-03</td>\n",
       "      <td>nM</td>\n",
       "      <td>CN(C)c1cc2c(Nc3cccc(Br)c3)ncnc2cn1</td>\n",
       "      <td>11.221849</td>\n",
       "      <td>343.043258</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.59690</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEMBL66031</td>\n",
       "      <td>8.000000e-03</td>\n",
       "      <td>nM</td>\n",
       "      <td>Brc1cccc(Nc2ncnc3cc4[nH]cnc4cc23)c1</td>\n",
       "      <td>11.096910</td>\n",
       "      <td>339.011957</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4.01220</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEMBL53753</td>\n",
       "      <td>8.000000e-03</td>\n",
       "      <td>nM</td>\n",
       "      <td>CNc1cc2c(Nc3cccc(Br)c3)ncnc2cn1</td>\n",
       "      <td>11.096910</td>\n",
       "      <td>329.027607</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.57260</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4630</th>\n",
       "      <td>CHEMBL120564</td>\n",
       "      <td>2.600000e+06</td>\n",
       "      <td>nM</td>\n",
       "      <td>COc1cc(C=C(C#N)C#N)cc(C)c1O</td>\n",
       "      <td>2.585027</td>\n",
       "      <td>214.074228</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.13978</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4631</th>\n",
       "      <td>CHEMBL66879</td>\n",
       "      <td>3.000000e+06</td>\n",
       "      <td>nM</td>\n",
       "      <td>O=C(O)/C=C/c1ccc(O)cc1</td>\n",
       "      <td>2.522879</td>\n",
       "      <td>164.047344</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.49000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632</th>\n",
       "      <td>CHEMBL261238</td>\n",
       "      <td>5.000000e+06</td>\n",
       "      <td>nM</td>\n",
       "      <td>CN(c1cccnc1)c1cc2c(Nc3ccc(F)c(Cl)c3)c(C#N)cnc2cn1</td>\n",
       "      <td>2.301030</td>\n",
       "      <td>404.095250</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5.20048</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4633</th>\n",
       "      <td>CHEMBL76587</td>\n",
       "      <td>6.500000e+06</td>\n",
       "      <td>nM</td>\n",
       "      <td>N#CC(C#N)Cc1ccc(O)cc1</td>\n",
       "      <td>2.187087</td>\n",
       "      <td>172.063663</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.59806</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4634</th>\n",
       "      <td>CHEMBL45068</td>\n",
       "      <td>2.500000e+07</td>\n",
       "      <td>nM</td>\n",
       "      <td>O=C(CCc1ccc(O)cc1)c1c(O)cc(O)cc1O</td>\n",
       "      <td>1.602060</td>\n",
       "      <td>274.084124</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.32450</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4635 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     molecule_chembl_id          IC50 units  \\\n",
       "0           CHEMBL63786  3.000000e-03    nM   \n",
       "1           CHEMBL35820  6.000000e-03    nM   \n",
       "2           CHEMBL53711  6.000000e-03    nM   \n",
       "3           CHEMBL66031  8.000000e-03    nM   \n",
       "4           CHEMBL53753  8.000000e-03    nM   \n",
       "...                 ...           ...   ...   \n",
       "4630       CHEMBL120564  2.600000e+06    nM   \n",
       "4631        CHEMBL66879  3.000000e+06    nM   \n",
       "4632       CHEMBL261238  5.000000e+06    nM   \n",
       "4633        CHEMBL76587  6.500000e+06    nM   \n",
       "4634        CHEMBL45068  2.500000e+07    nM   \n",
       "\n",
       "                                                 smiles      pIC50  \\\n",
       "0                     Brc1cccc(Nc2ncnc3cc4ccccc4cc23)c1  11.522879   \n",
       "1                   CCOc1cc2ncnc(Nc3cccc(Br)c3)c2cc1OCC  11.221849   \n",
       "2                    CN(C)c1cc2c(Nc3cccc(Br)c3)ncnc2cn1  11.221849   \n",
       "3                   Brc1cccc(Nc2ncnc3cc4[nH]cnc4cc23)c1  11.096910   \n",
       "4                       CNc1cc2c(Nc3cccc(Br)c3)ncnc2cn1  11.096910   \n",
       "...                                                 ...        ...   \n",
       "4630                        COc1cc(C=C(C#N)C#N)cc(C)c1O   2.585027   \n",
       "4631                             O=C(O)/C=C/c1ccc(O)cc1   2.522879   \n",
       "4632  CN(c1cccnc1)c1cc2c(Nc3ccc(F)c(Cl)c3)c(C#N)cnc2cn1   2.301030   \n",
       "4633                              N#CC(C#N)Cc1ccc(O)cc1   2.187087   \n",
       "4634                  O=C(CCc1ccc(O)cc1)c1c(O)cc(O)cc1O   1.602060   \n",
       "\n",
       "      molecular_weight  n_hba  n_hbd     logp  ro5_fulfilled  \n",
       "0           349.021459      3      1  5.28910           True  \n",
       "1           387.058239      5      1  4.93330           True  \n",
       "2           343.043258      5      1  3.59690           True  \n",
       "3           339.011957      4      2  4.01220           True  \n",
       "4           329.027607      5      2  3.57260           True  \n",
       "...                ...    ...    ...      ...            ...  \n",
       "4630        214.074228      4      1  2.13978           True  \n",
       "4631        164.047344      2      2  1.49000           True  \n",
       "4632        404.095250      6      1  5.20048           True  \n",
       "4633        172.063663      3      1  1.59806           True  \n",
       "4634        274.084124      5      4  2.32450           True  \n",
       "\n",
       "[4635 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = utils.download_data(filename='dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e576fd45-cc11-44f4-aa73-4d2b6ad48a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>pIC50</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brc1cccc(Nc2ncnc3cc4ccccc4cc23)c1</td>\n",
       "      <td>11.522879</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCOc1cc2ncnc(Nc3cccc(Br)c3)c2cc1OCC</td>\n",
       "      <td>11.221849</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CN(C)c1cc2c(Nc3cccc(Br)c3)ncnc2cn1</td>\n",
       "      <td>11.221849</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brc1cccc(Nc2ncnc3cc4[nH]cnc4cc23)c1</td>\n",
       "      <td>11.096910</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNc1cc2c(Nc3cccc(Br)c3)ncnc2cn1</td>\n",
       "      <td>11.096910</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4630</th>\n",
       "      <td>COc1cc(C=C(C#N)C#N)cc(C)c1O</td>\n",
       "      <td>2.585027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4631</th>\n",
       "      <td>O=C(O)/C=C/c1ccc(O)cc1</td>\n",
       "      <td>2.522879</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632</th>\n",
       "      <td>CN(c1cccnc1)c1cc2c(Nc3ccc(F)c(Cl)c3)c(C#N)cnc2cn1</td>\n",
       "      <td>2.301030</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4633</th>\n",
       "      <td>N#CC(C#N)Cc1ccc(O)cc1</td>\n",
       "      <td>2.187087</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4634</th>\n",
       "      <td>O=C(CCc1ccc(O)cc1)c1c(O)cc(O)cc1O</td>\n",
       "      <td>1.602060</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4635 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 smiles      pIC50  active\n",
       "0                     Brc1cccc(Nc2ncnc3cc4ccccc4cc23)c1  11.522879     1.0\n",
       "1                   CCOc1cc2ncnc(Nc3cccc(Br)c3)c2cc1OCC  11.221849     1.0\n",
       "2                    CN(C)c1cc2c(Nc3cccc(Br)c3)ncnc2cn1  11.221849     1.0\n",
       "3                   Brc1cccc(Nc2ncnc3cc4[nH]cnc4cc23)c1  11.096910     1.0\n",
       "4                       CNc1cc2c(Nc3cccc(Br)c3)ncnc2cn1  11.096910     1.0\n",
       "...                                                 ...        ...     ...\n",
       "4630                        COc1cc(C=C(C#N)C#N)cc(C)c1O   2.585027     0.0\n",
       "4631                             O=C(O)/C=C/c1ccc(O)cc1   2.522879     0.0\n",
       "4632  CN(c1cccnc1)c1cc2c(Nc3ccc(F)c(Cl)c3)c(C#N)cnc2cn1   2.301030     0.0\n",
       "4633                              N#CC(C#N)Cc1ccc(O)cc1   2.187087     0.0\n",
       "4634                  O=C(CCc1ccc(O)cc1)c1c(O)cc(O)cc1O   1.602060     0.0\n",
       "\n",
       "[4635 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"smiles\", \"pIC50\"]]\n",
    "# Add column for activity\n",
    "df[\"active\"] = np.zeros(len(df))\n",
    "\n",
    "# Mark every molecule as active with an pIC50 of >= 8.0, 0 otherwise\n",
    "pIC50_cut_off = 8.0\n",
    "df.loc[df[df.pIC50 >= pIC50_cut_off].index, \"active\"] = 1.0\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ac5fd5-7b24-4c7c-a5eb-9cc332aff067",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54493e44-cba0-422a-9235-02a9c0776fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>pIC50</th>\n",
       "      <th>active</th>\n",
       "      <th>finger print</th>\n",
       "      <th>selfies</th>\n",
       "      <th>mordred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brc1cccc(Nc2ncnc3cc4ccccc4cc23)c1</td>\n",
       "      <td>11.522879</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Br][C][=C][C][=C][C][Branch2][Ring1][=Branch1...</td>\n",
       "      <td>[0.0, 0.0, 20.0, 22.0, 34.0, 22.0, 0.0, 0.0, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCOc1cc2ncnc(Nc3cccc(Br)c3)c2cc1OCC</td>\n",
       "      <td>11.221849</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[C][C][O][C][=C][C][=N][C][=N][C][Branch1][=N]...</td>\n",
       "      <td>[0.0, 0.0, 16.0, 17.0, 42.0, 24.0, 0.0, 0.0, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CN(C)c1cc2c(Nc3cccc(Br)c3)ncnc2cn1</td>\n",
       "      <td>11.221849</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[C][N][Branch1][C][C][C][=C][C][=C][Branch1][=...</td>\n",
       "      <td>[0.0, 0.0, 16.0, 17.0, 35.0, 21.0, 0.0, 0.0, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brc1cccc(Nc2ncnc3cc4[nH]cnc4cc23)c1</td>\n",
       "      <td>11.096910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Br][C][=C][C][=C][C][Branch2][Ring1][Branch1]...</td>\n",
       "      <td>[0.0, 0.0, 19.0, 21.0, 31.0, 21.0, 0.0, 0.0, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNc1cc2c(Nc3cccc(Br)c3)ncnc2cn1</td>\n",
       "      <td>11.096910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[C][N][C][=C][C][=C][Branch1][=N][N][C][=C][C]...</td>\n",
       "      <td>[0.0, 0.0, 16.0, 17.0, 32.0, 20.0, 0.0, 0.0, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4630</th>\n",
       "      <td>COc1cc(C=C(C#N)C#N)cc(C)c1O</td>\n",
       "      <td>2.585027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[C][O][C][=C][C][Branch1][=Branch2][C][=C][Bra...</td>\n",
       "      <td>[0.0, 0.0, 6.0, 6.0, 26.0, 16.0, 0.0, 0.0, 4.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4631</th>\n",
       "      <td>O=C(O)/C=C/c1ccc(O)cc1</td>\n",
       "      <td>2.522879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[O][=C][Branch1][C][O][/C][=C][/C][=C][C][=C][...</td>\n",
       "      <td>[1.0, 0.0, 6.0, 6.0, 20.0, 12.0, 0.0, 0.0, 3.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632</th>\n",
       "      <td>CN(c1cccnc1)c1cc2c(Nc3ccc(F)c(Cl)c3)c(C#N)cnc2cn1</td>\n",
       "      <td>2.301030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[C][N][Branch1][=Branch2][C][=C][C][=C][N][=C]...</td>\n",
       "      <td>[0.0, 0.0, 22.0, 23.0, 43.0, 29.0, 0.0, 0.0, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4633</th>\n",
       "      <td>N#CC(C#N)Cc1ccc(O)cc1</td>\n",
       "      <td>2.187087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[N][#C][C][Branch1][Ring1][C][#N][C][C][=C][C]...</td>\n",
       "      <td>[0.0, 0.0, 6.0, 6.0, 21.0, 13.0, 0.0, 0.0, 3.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4634</th>\n",
       "      <td>O=C(CCc1ccc(O)cc1)c1c(O)cc(O)cc1O</td>\n",
       "      <td>1.602060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[O][=C][Branch1][=C][C][C][C][=C][C][=C][Branc...</td>\n",
       "      <td>[0.0, 0.0, 12.0, 12.0, 34.0, 20.0, 0.0, 0.0, 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4635 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 smiles      pIC50  active  \\\n",
       "0                     Brc1cccc(Nc2ncnc3cc4ccccc4cc23)c1  11.522879     1.0   \n",
       "1                   CCOc1cc2ncnc(Nc3cccc(Br)c3)c2cc1OCC  11.221849     1.0   \n",
       "2                    CN(C)c1cc2c(Nc3cccc(Br)c3)ncnc2cn1  11.221849     1.0   \n",
       "3                   Brc1cccc(Nc2ncnc3cc4[nH]cnc4cc23)c1  11.096910     1.0   \n",
       "4                       CNc1cc2c(Nc3cccc(Br)c3)ncnc2cn1  11.096910     1.0   \n",
       "...                                                 ...        ...     ...   \n",
       "4630                        COc1cc(C=C(C#N)C#N)cc(C)c1O   2.585027     0.0   \n",
       "4631                             O=C(O)/C=C/c1ccc(O)cc1   2.522879     0.0   \n",
       "4632  CN(c1cccnc1)c1cc2c(Nc3ccc(F)c(Cl)c3)c(C#N)cnc2cn1   2.301030     0.0   \n",
       "4633                              N#CC(C#N)Cc1ccc(O)cc1   2.187087     0.0   \n",
       "4634                  O=C(CCc1ccc(O)cc1)c1c(O)cc(O)cc1O   1.602060     0.0   \n",
       "\n",
       "                                           finger print  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "4630  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4631  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4632  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "4633  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4634  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                selfies  \\\n",
       "0     [Br][C][=C][C][=C][C][Branch2][Ring1][=Branch1...   \n",
       "1     [C][C][O][C][=C][C][=N][C][=N][C][Branch1][=N]...   \n",
       "2     [C][N][Branch1][C][C][C][=C][C][=C][Branch1][=...   \n",
       "3     [Br][C][=C][C][=C][C][Branch2][Ring1][Branch1]...   \n",
       "4     [C][N][C][=C][C][=C][Branch1][=N][N][C][=C][C]...   \n",
       "...                                                 ...   \n",
       "4630  [C][O][C][=C][C][Branch1][=Branch2][C][=C][Bra...   \n",
       "4631  [O][=C][Branch1][C][O][/C][=C][/C][=C][C][=C][...   \n",
       "4632  [C][N][Branch1][=Branch2][C][=C][C][=C][N][=C]...   \n",
       "4633  [N][#C][C][Branch1][Ring1][C][#N][C][C][=C][C]...   \n",
       "4634  [O][=C][Branch1][=C][C][C][C][=C][C][=C][Branc...   \n",
       "\n",
       "                                                mordred  \n",
       "0     [0.0, 0.0, 20.0, 22.0, 34.0, 22.0, 0.0, 0.0, 4...  \n",
       "1     [0.0, 0.0, 16.0, 17.0, 42.0, 24.0, 0.0, 0.0, 6...  \n",
       "2     [0.0, 0.0, 16.0, 17.0, 35.0, 21.0, 0.0, 0.0, 6...  \n",
       "3     [0.0, 0.0, 19.0, 21.0, 31.0, 21.0, 0.0, 0.0, 6...  \n",
       "4     [0.0, 0.0, 16.0, 17.0, 32.0, 20.0, 0.0, 0.0, 6...  \n",
       "...                                                 ...  \n",
       "4630  [0.0, 0.0, 6.0, 6.0, 26.0, 16.0, 0.0, 0.0, 4.0...  \n",
       "4631  [1.0, 0.0, 6.0, 6.0, 20.0, 12.0, 0.0, 0.0, 3.0...  \n",
       "4632  [0.0, 0.0, 22.0, 23.0, 43.0, 29.0, 0.0, 0.0, 8...  \n",
       "4633  [0.0, 0.0, 6.0, 6.0, 21.0, 13.0, 0.0, 0.0, 3.0...  \n",
       "4634  [0.0, 0.0, 12.0, 12.0, 34.0, 20.0, 0.0, 0.0, 5...  \n",
       "\n",
       "[4635 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"finger print\"] = df[\"smiles\"].apply(utils.smiles_to_descriptors, type='morgan2')\n",
    "df[\"selfies\"] = df[\"smiles\"].apply(utils.smiles_to_descriptors, type='selfies')\n",
    "\n",
    "# Mordred takes forever to run, so just loading the pickled file!\n",
    "morderd_file = 'mordred_descriptors.pkl'\n",
    "if not os.path.exists(morderd_file):\n",
    "    df['mordred'] = df[\"smiles\"].apply(utils.smiles_to_descriptors, type='mordred')\n",
    "    df['mordred'] = [list(array[0]) for array in df['mordred']]\n",
    "    # Identify columns with NaN values\n",
    "    nan_columns = np.isnan(np.vstack(df['mordred'])).any(axis=0)\n",
    "    # Extract columns without NaN values\n",
    "    mordred_array_without_nan = mordred_array[:, ~nan_columns]\n",
    "    # dropping features with 0 std\n",
    "    mask = mordred_array_without_nan.std(axis=0) != 0\n",
    "    mordred_array_without_nan = mordred_array_without_nan[:, mask]\n",
    "    df['mordred'] = mordred_array_without_nan.tolist()\n",
    "    df['mordred'].to_pickle('mordred_descriptors.pkl')\n",
    "else:\n",
    "    df['mordred'] = pd.read_pickle('mordred_descriptors.pkl')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c7b3f2-b738-43ee-86fd-ad50ab58aee4",
   "metadata": {},
   "source": [
    "### RNN model features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a1706-b667-40b1-b8be-47fc8f99314f",
   "metadata": {},
   "source": [
    "Converting Smiles to SELFIES and creating an integer encoding for them selfies by tokenizing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3231b02-04f5-49c8-8016-383e18871bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 58,\n",
       " '[#Branch1]': 1,\n",
       " '[#Branch2]': 2,\n",
       " '[#C]': 3,\n",
       " '[#N]': 4,\n",
       " '[/C@@H1]': 5,\n",
       " '[/C@H1]': 6,\n",
       " '[/C]': 7,\n",
       " '[/Cl]': 8,\n",
       " '[/F]': 9,\n",
       " '[/N+1]': 10,\n",
       " '[/N]': 11,\n",
       " '[/O]': 12,\n",
       " '[=Branch1]': 13,\n",
       " '[=Branch2]': 14,\n",
       " '[=C]': 15,\n",
       " '[=N+1]': 16,\n",
       " '[=N-1]': 17,\n",
       " '[=N]': 18,\n",
       " '[=O+1]': 19,\n",
       " '[=O]': 20,\n",
       " '[=P]': 21,\n",
       " '[=Ring1]': 22,\n",
       " '[=Ring2]': 23,\n",
       " '[=S]': 24,\n",
       " '[B]': 25,\n",
       " '[Br-1]': 26,\n",
       " '[Br]': 27,\n",
       " '[Branch1]': 28,\n",
       " '[Branch2]': 29,\n",
       " '[C@@H1]': 30,\n",
       " '[C@@]': 31,\n",
       " '[C@H1]': 32,\n",
       " '[C@]': 33,\n",
       " '[C]': 34,\n",
       " '[Cl-1]': 35,\n",
       " '[Cl]': 36,\n",
       " '[F]': 37,\n",
       " '[I]': 38,\n",
       " '[N+1]': 39,\n",
       " '[NH1]': 40,\n",
       " '[N]': 41,\n",
       " '[O-1]': 42,\n",
       " '[OH0]': 43,\n",
       " '[O]': 44,\n",
       " '[P]': 45,\n",
       " '[Ring1]': 46,\n",
       " '[Ring2]': 47,\n",
       " '[S+1]': 48,\n",
       " '[S]': 49,\n",
       " '[Se]': 50,\n",
       " '[Si]': 51,\n",
       " '[Zn+2]': 52,\n",
       " '[\\\\C]': 53,\n",
       " '[\\\\F]': 54,\n",
       " '[\\\\N]': 55,\n",
       " '[\\\\O]': 56,\n",
       " '[\\\\S]': 57,\n",
       " '[nop]': 0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selfies as sf\n",
    "alphabet = sf.get_alphabet_from_selfies(df['selfies'].to_list())\n",
    "alphabet.add('[nop]') # This is a special padding symbol\n",
    "alphabet.add('.')\n",
    "alphabet = list(sorted(alphabet))\n",
    "voc = {s: i for i, s in enumerate(alphabet)}\n",
    "pad_to_len = max(sf.len_selfies(s) for s in df[\"selfies\"])\n",
    "voc['[nop]'] = 0 # This will be masked in the trainable embedding layer\n",
    "voc['.'] = 58\n",
    "df['encoding'] = df[\"selfies\"].apply(utils.selfies_to_encoding, vocab_stoi=voc, pad_to_len=pad_to_len)\n",
    "voc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b943079d-f30e-4189-bcbc-7fd4c30a90a1",
   "metadata": {},
   "source": [
    "## Train, Validation Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ffb7a13-1ea8-4d81-8039-d283b4e497db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 3708\n",
      "Val size: 463\n",
      "Test size: 464\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "SEED = 22\n",
    "\n",
    "X = np.vstack(df['finger print'])\n",
    "y = np.vstack(df['active'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Second split: Split into half for validation and test sets (i.e., 10% each of original data)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=SEED)\n",
    "\n",
    "splits = [X_train, X_val, y_train, y_val]\n",
    "\n",
    "print(f\"Training size: {len(X_train)}\")\n",
    "print(f\"Val size: {len(y_val)}\")\n",
    "print(f\"Test size: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b24b2e6-ad96-4cc1-8ae7-3919dc27ae8d",
   "metadata": {},
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3fed9d-7288-463b-b991-54d4e75cbbc4",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7198d561-a7d4-45e9-806a-251a430b061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Set model parameter for random forest\n",
    "param = {\n",
    "    \"n_estimators\": 50,  # number of trees to grows\n",
    "    \"criterion\": \"entropy\",  # loss function to be optimized for a split\n",
    "}\n",
    "model_RF = RandomForestClassifier(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73efa3bc-8b72-4a16-bbfd-65dde9970eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n",
      "AUC: 0.89\n",
      "f1 score: 0.59\n"
     ]
    }
   ],
   "source": [
    "# Fit model on single split\n",
    "performance_measures = utils.model_training_and_validation(model_RF, \"RF\", splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c799db-01fd-42a9-a003-49a467833403",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fec22c5a-4fd9-4a4a-ab93-d97d72b1f5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n",
      "AUC: 0.90\n",
      "f1 score: 0.61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Specify model\n",
    "model_lr = LogisticRegression(max_iter=2000)\n",
    "# Fit model on single split\n",
    "performance_measures = utils.model_training_and_validation(model_lr, \"LR\", splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bb3e3f-3b18-43bd-bd47-a3137a088748",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e07586-fec2-4f57-a289-4acac375db7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "X_e = np.vstack(df['encoding'])\n",
    "X_= np.vstack(df['finger print'])\n",
    "# X_m = np.vstack(df['other desc'])\n",
    "X_m = mordred_array_without_nan\n",
    "X = np.concatenate([X_e, X_,X_m],axis=1)\n",
    "\n",
    "\n",
    "y = np.vstack(df['active'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Second split: Split into half for validation and test sets (i.e., 10% each of original data)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=SEED)\n",
    "\n",
    "\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# oversample = SMOTE()\n",
    "# X_train, y_train = oversample.fit_resample(X_train,y_train)\n",
    "\n",
    "# oversample = SMOTE()\n",
    "# X_train, y_train = oversample.fit_resample(X_train,y_train)\n",
    "\n",
    "splits = [X_train, X_val, y_train, y_val]\n",
    "\n",
    "print(f\"Training size: {len(X_train)}\")\n",
    "print(f\"Val size: {len(y_val)}\")\n",
    "print(f\"Test size: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba70c948-b904-4541-b203-f41a3da8d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from dataclasses import dataclass\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "class RNNModel(tf.keras.Model):\n",
    "    def __init__(self, config, input_shapes, output_bias=None, **kwargs):\n",
    "        super(RNNModel, self).__init__(**kwargs)\n",
    "        self.config = config\n",
    "        self.l, self.f, self.m  = input_shapes\n",
    "        # self.f = f\n",
    "        # self.m = m\n",
    "        self.output_bias = output_bias\n",
    "        self.model = self.build_LSTM_model()\n",
    "\n",
    "    def build_LSTM_model(self):\n",
    "        tf.keras.backend.clear_session()\n",
    "        input = tf.keras.Input(shape=(self.l,))\n",
    "        input_f = tf.keras.Input(shape=(self.f,))\n",
    "        # input_f = tf.keras.layers.Reshape((self.f,1))(input_f)\n",
    "        input_m = tf.keras.Input(shape=(self.m,))\n",
    "\n",
    "        e = tf.keras.layers.Embedding(\n",
    "            input_dim=self.config.vocab_size,\n",
    "            output_dim=self.config.embedding_dim,\n",
    "            mask_zero=True)(input)\n",
    "        x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(self.config.rnn_units, return_sequences=True))(e)\n",
    "        x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(self.config.rnn_units, activation=None))(x)\n",
    "        x = tf.keras.layers.LayerNormalization()(x)\n",
    "        # x_f = tf.keras.layers.Conv1D(filters=self.config.cnn_filter, \n",
    "        #            kernel_size=self.config.cnn_kernel_size, \n",
    "        #            activation='relu')(input_f)\n",
    "        # x_f =  tf.keras.layers.LayerNormalization()(x_f)\n",
    "        # x_f = tf.keras.layers.Dropout(self.config.drop_rate)(x_f)    \n",
    "        # x_f = tf.keras.layers.MaxPooling1D(pool_size=self.config.pool_size)(x_f)\n",
    "        # x_f = tf.keras.layers.Flatten()(x_f)\n",
    "        \n",
    "        x = tf.keras.layers.Concatenate()([x, input_f]) # input_f\n",
    "        x = tf.keras.layers.Dropout(self.config.drop_rate)(x)\n",
    "        \n",
    "        x = tf.keras.layers.Dense(\n",
    "            self.config.hidden_dim,\n",
    "            # activation='relu',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(self.config.reg_strength))(x)\n",
    "        x = tf.keras.layers.LayerNormalization()(x)\n",
    "        x = tf.keras.layers.Concatenate(axis=1)([x, input_m])\n",
    "        x = tf.keras.layers.Dense(\n",
    "            self.config.hidden_dim//4,\n",
    "            # activation='swish',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(self.config.reg_strength))(x)\n",
    "        x = tf.keras.layers.LayerNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(self.config.drop_rate)(x)\n",
    "        \n",
    "        # x = tf.keras.layers.Dense(\n",
    "        #     self.config.hidden_dim // 8,\n",
    "        #     # activation='swish',\n",
    "        #     kernel_regularizer=tf.keras.regularizers.l2(self.config.reg_strength))(x)\n",
    "        # x = tf.keras.layers.LayerNormalization()(x)\n",
    "        \n",
    "        output = tf.keras.layers.Dense(1, activation='sigmoid', bias_initializer=None)(x)\n",
    "\n",
    "        return tf.keras.Model(inputs=[input, input_f, input_m], outputs=output, name='LSTM')\n",
    "\n",
    "    def compile(self):\n",
    "        opt = tf.optimizers.Adam(self.config.lr)\n",
    "        self.model.compile(\n",
    "            opt,\n",
    "            loss= tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "            metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5),\n",
    "                     tf.keras.metrics.AUC(from_logits=False),\n",
    "                    tf.keras.metrics.F1Score(threshold=0.5)]) \n",
    "\n",
    "    def train(self, X_train_input, X_train_input_f, X_train_input_m,\n",
    "              y_train, X_test_input, X_test_input_f, X_test_input_m, y_test, verbose=1):\n",
    "        self.compile()\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_auc',\n",
    "                                      factor=0.9,\n",
    "                                      patience=8,\n",
    "                                      min_lr=0.00001,\n",
    "                                      )\n",
    "        \n",
    "        self.result = self.model.fit(\n",
    "            [X_train_input, X_train_input_f, X_train_input_m], y_train,\n",
    "            validation_data=([X_test_input, X_test_input_f, X_test_input_m], y_test),\n",
    "            callbacks=[reduce_lr, \n",
    "                       tf.keras.callbacks.EarlyStopping(monitor='val_auc', mode='max', \n",
    "                                                        restore_best_weights=True, patience=self.config.early_stopping_patience)],\n",
    "            epochs=self.config.epochs, batch_size=self.config.batch_size, verbose=verbose)\n",
    "\n",
    "    def evaluate(self, x, y, **kwargs):\n",
    "        \"\"\"Evaluate the model on the provided data.\"\"\"\n",
    "        return self.model.evaluate(x, y, **kwargs)\n",
    "        \n",
    "    def summary(self):\n",
    "        \"\"\"Prints a summary representation of the keras model.\"\"\"\n",
    "        self.model.summary()\n",
    "\n",
    "# Example usage:\n",
    "# rnn_model = RNNModel(lstm_config, L)\n",
    "# rnn_model.compile()\n",
    "# rnn_model.train(X_train_input, X_train_input_f, X_train_input_m, y_train, X_test_input, X_test_input_f, X_test_input_m, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "90a4b0d6-5fcd-47e3-a5c4-c03782ac97f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LSTM_Config:\n",
    "    vocab_size: int = len(voc)\n",
    "    batch_size: int = 64\n",
    "    buffer_size: int = 10000\n",
    "    rnn_units: int = 16\n",
    "    hidden_dim: int = 32\n",
    "    embedding_dim: int = 8\n",
    "    reg_strength: float = 0\n",
    "    lr: float = 1e-3\n",
    "    drop_rate: float = 0.2\n",
    "    epochs: int = 100\n",
    "    nmodels: int = 1\n",
    "    adv_epsilon: float = 1e-3\n",
    "    early_stopping_patience = 5\n",
    "    cnn_filter = 16\n",
    "    cnn_kernel_size = 5\n",
    "    cnn_units = 16\n",
    "    pool_size = 10\n",
    "    \n",
    "\n",
    "lstm_config = LSTM_Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c7789883-88f4-41e5-9fd1-cc06e3c8e088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def prepare_RNN_data(X_train, X_val, X_test, j, k, selected_feature_indices=None):\n",
    "    \"\"\"\n",
    "    Prepares data by slicing and scaling.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train, X_val, X_test: input datasets\n",
    "    - j, k: indices for slicing\n",
    "    - selected_feature_indices (optional): indices for feature selection. If None, all are considered.\n",
    "\n",
    "    Returns:\n",
    "    Sliced and scaled datasets.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Slicing\n",
    "    X_train_input_f = X_train[:, -j:-k]\n",
    "    X_val_input_f = X_val[:, -j:-k]\n",
    "    X_test_input_f = X_test[:, -j:-k]\n",
    "\n",
    "    # If selected_feature_indices is None, consider all columns in the range\n",
    "    if selected_feature_indices is None:\n",
    "        X_train_input_m = X_train[:, -k:]\n",
    "        X_val_input_m = X_val[:, -k:]\n",
    "        X_test_input_m = X_test[:, -k:]\n",
    "    else:\n",
    "        X_train_input_m = X_train[:, -k:][:, selected_feature_indices]\n",
    "        X_val_input_m = X_val[:, -k:][:, selected_feature_indices]\n",
    "        X_test_input_m = X_test[:, -k:][:, selected_feature_indices]\n",
    "\n",
    "    # Scaling\n",
    "    scaler = StandardScaler().fit(X_train_input_m)\n",
    "    X_train_input_m = scaler.transform(X_train_input_m) \n",
    "    X_val_input_m = scaler.transform(X_val_input_m) \n",
    "    X_test_input_m = scaler.transform(X_test_input_m)\n",
    "\n",
    "    X_train_input = X_train[:, :-j]\n",
    "    X_val_input = X_val[:, :-j]\n",
    "    X_test_input = X_test[:, :-j]\n",
    "\n",
    "    return (X_train_input, X_train_input_f, X_train_input_m, \n",
    "            X_val_input, X_val_input_f, X_val_input_m,\n",
    "            X_test_input, X_test_input_f, X_test_input_m)\n",
    "\n",
    "# Example usage:\n",
    "# X_train_input, X_train_input_f, X_train_input_m, X_val_input, X_val_input_f, X_val_input_m, X_test_input, X_test_input\n",
    "\n",
    "\n",
    "# [25, 114, 125, 126, 127, 129, 132, 134, 135, 136, 137, 138, 142, 145, 148, 151, 154, 155,\n",
    "#          158, 160, 163, 165, 167, 169, 170, 171, 172, 176, 178, 180, 185, 189, 190, 192, 194, 196,\n",
    "#          198, 199, 203, 205, 206, 207, 208, 210, 220, 221, 260, 261, 264, 316, 340, 343, 349, 350,\n",
    "#          354, 358, 386, 387, 389, 400, 404, 410, 417, 423, 428, 429, 431, 433, 434, 441, 445, 452,\n",
    "#          455, 459, 462, 464, 468, 469, 470, 471, 472, 473, 474, 489, 490, 491, 492, 493, 494, 495,\n",
    "#          496, 600, 606, 609, 613, 616, 617, 618, 620, 623] 0.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0ee9080c-a035-4ade-b018-4751c4b78315",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_indices = [26, 27, 48, 55, 72, 124, 125, 126, 127, 129, 132, 133, 135, 136, 137, 138, 142, 143,\n",
    "         144, 145, 147, 148, 150, 151, 153, 154, 155, 156, 158, 160, 163, 164, 165, 167, 168, 169,\n",
    "         170, 171, 172, 173, 174, 176, 177, 179, 180, 181, 185, 186, 188, 190, 192, 193, 194, 196,\n",
    "         197, 199, 200, 201, 203, 204, 206, 207, 209, 210, 211, 220, 251, 260, 261, 263, 265, 270,\n",
    "         271, 272, 295, 316, 343, 344, 349, 350, 354, 358, 386, 387, 399, 409, 410, 416, 417, 418,\n",
    "         423, 426, 428, 429, 431, 433, 434, 441, 445, 452, 455, 459, 464, 468, 469, 470, 471, 472,\n",
    "         473, 474, 488, 489, 491, 492, 493, 494, 495, 496, 514, 527, 600, 602, 603, 612, 613, 616,\n",
    "         617, 618, 623, 638] \n",
    "\n",
    "# selected_feature_indices = [ 12, 203, 298, 312, 316, 340, 354, 358, 387, 388, 444, 455, 503,\n",
    "#        514, 523, 527, 556, 565, 572, 578]\n",
    "\n",
    "\n",
    "\n",
    "j = X_train.shape[1]- len(df['encoding'].iloc[0])\n",
    "k = mordred_array_without_nan.shape[1]\n",
    "\n",
    "X_train_input, X_train_input_f, X_train_input_m, \\\n",
    "X_val_input, X_val_input_f, X_val_input_m, \\\n",
    "X_test_input, X_test_input_f, X_test_input_m = prepare_RNN_data(\n",
    "    X_train, X_val, X_test, j, k, selected_feature_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ed3a118c-b6d2-44fb-a48f-473726dd8dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# j = X_train.shape[1]- len(df['encoding'].iloc[0])\n",
    "# print(j)\n",
    "#  # k = len(df['other desc'].iloc[0])\n",
    "# k = mordred_array_without_nan.shape[1]\n",
    "# print(k)\n",
    "\n",
    "# selected_feature_indices = [ 12, 203, 298, 312, 316, 340, 354, 358, 387, 388, 444, 455, 503,\n",
    "#        514, 523, 527, 556, 565, 572, 578]\n",
    "\n",
    "# X_train_input_f = X_train[:, -j:-k]\n",
    "# X_val_input_f = X_val[:, -j:-k]\n",
    "# X_test_input_f = X_test[:, -j:-k]\n",
    "# X_train_input_m = X_train[:, -k:][:, selected_feature_indices]\n",
    "# X_val_input_m = X_val[:, -k:][:, selected_feature_indices]\n",
    "# X_test_input_m = X_test[:, -k:][:, selected_feature_indices]\n",
    "\n",
    "# scaler = StandardScaler().fit(X_train_input_m)\n",
    "# X_train_input_m = scaler.transform(X_train_input_m) \n",
    "# X_test_input_m = scaler.transform(X_test_input_m) \n",
    "# X_val_input_m = scaler.transform(X_val_input_m) \n",
    "\n",
    "\n",
    "# X_train_input = X_train[:, :-j]\n",
    "# X_test_input = X_test[:, :-j]\n",
    "# X_val_input = X_val[:, :-j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "922167f1-fd61-4a5e-847a-82e278bc38d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 87)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 87, 8)                472       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 87, 32)               3200      ['embedding[0][0]']           \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirecti  (None, 32)                   6272      ['bidirectional[0][0]']       \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " layer_normalization (Layer  (None, 32)                   64        ['bidirectional_1[0][0]']     \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 1024)]               0         []                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 1056)                 0         ['layer_normalization[0][0]', \n",
      "                                                                     'input_2[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 1056)                 0         ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 32)                   33824     ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_1 (Lay  (None, 32)                   64        ['dense[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, 130)]                0         []                            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 162)                  0         ['layer_normalization_1[0][0]'\n",
      " )                                                                  , 'input_3[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 8)                    1304      ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " layer_normalization_2 (Lay  (None, 8)                    16        ['dense_1[0][0]']             \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 8)                    0         ['layer_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    9         ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 45225 (176.66 KB)\n",
      "Trainable params: 45225 (176.66 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shapes = [X_train_input.shape[1], X_train_input_f.shape[1], X_train_input_m.shape[1]]\n",
    "rnn_model = RNNModel(lstm_config, input_shapes)\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8b15d5bf-bb4e-4f81-9edf-ccf99d31c0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "58/58 [==============================] - 45s 313ms/step - loss: 0.5196 - binary_accuracy: 0.7840 - auc: 0.6344 - f1_score: 0.2549 - val_loss: 0.4044 - val_binary_accuracy: 0.8229 - val_auc: 0.8010 - val_f1_score: 0.2807 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 11s 193ms/step - loss: 0.3891 - binary_accuracy: 0.8285 - auc: 0.8059 - f1_score: 0.4133 - val_loss: 0.3426 - val_binary_accuracy: 0.8553 - val_auc: 0.8630 - val_f1_score: 0.5248 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 11s 195ms/step - loss: 0.3525 - binary_accuracy: 0.8463 - auc: 0.8489 - f1_score: 0.5161 - val_loss: 0.3287 - val_binary_accuracy: 0.8531 - val_auc: 0.8799 - val_f1_score: 0.4848 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 11s 196ms/step - loss: 0.3194 - binary_accuracy: 0.8617 - auc: 0.8811 - f1_score: 0.5792 - val_loss: 0.3410 - val_binary_accuracy: 0.8553 - val_auc: 0.8779 - val_f1_score: 0.4640 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 11s 193ms/step - loss: 0.3138 - binary_accuracy: 0.8630 - auc: 0.8864 - f1_score: 0.5955 - val_loss: 0.3144 - val_binary_accuracy: 0.8812 - val_auc: 0.8856 - val_f1_score: 0.6259 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 11s 195ms/step - loss: 0.2903 - binary_accuracy: 0.8773 - auc: 0.9041 - f1_score: 0.6363 - val_loss: 0.3077 - val_binary_accuracy: 0.8726 - val_auc: 0.8907 - val_f1_score: 0.6242 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 11s 193ms/step - loss: 0.2705 - binary_accuracy: 0.8843 - auc: 0.9185 - f1_score: 0.6635 - val_loss: 0.3087 - val_binary_accuracy: 0.8812 - val_auc: 0.8904 - val_f1_score: 0.6497 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 11s 193ms/step - loss: 0.2688 - binary_accuracy: 0.8824 - auc: 0.9213 - f1_score: 0.6636 - val_loss: 0.3106 - val_binary_accuracy: 0.8790 - val_auc: 0.8896 - val_f1_score: 0.6410 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 11s 194ms/step - loss: 0.2637 - binary_accuracy: 0.8859 - auc: 0.9220 - f1_score: 0.6744 - val_loss: 0.3076 - val_binary_accuracy: 0.8747 - val_auc: 0.8993 - val_f1_score: 0.6548 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - 11s 192ms/step - loss: 0.2538 - binary_accuracy: 0.8943 - auc: 0.9288 - f1_score: 0.6942 - val_loss: 0.3178 - val_binary_accuracy: 0.8726 - val_auc: 0.8989 - val_f1_score: 0.6845 - lr: 9.0000e-04\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - 11s 195ms/step - loss: 0.2517 - binary_accuracy: 0.8913 - auc: 0.9311 - f1_score: 0.6972 - val_loss: 0.2979 - val_binary_accuracy: 0.8898 - val_auc: 0.9027 - val_f1_score: 0.6667 - lr: 9.0000e-04\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - 11s 193ms/step - loss: 0.2458 - binary_accuracy: 0.8921 - auc: 0.9347 - f1_score: 0.6904 - val_loss: 0.2999 - val_binary_accuracy: 0.8898 - val_auc: 0.9014 - val_f1_score: 0.6752 - lr: 9.0000e-04\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - 11s 194ms/step - loss: 0.2373 - binary_accuracy: 0.8991 - auc: 0.9395 - f1_score: 0.7188 - val_loss: 0.3033 - val_binary_accuracy: 0.8790 - val_auc: 0.9033 - val_f1_score: 0.6364 - lr: 9.0000e-04\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - 11s 195ms/step - loss: 0.2275 - binary_accuracy: 0.9018 - auc: 0.9456 - f1_score: 0.7251 - val_loss: 0.3044 - val_binary_accuracy: 0.8834 - val_auc: 0.9006 - val_f1_score: 0.6538 - lr: 9.0000e-04\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - 11s 196ms/step - loss: 0.2286 - binary_accuracy: 0.9002 - auc: 0.9444 - f1_score: 0.7176 - val_loss: 0.2974 - val_binary_accuracy: 0.8790 - val_auc: 0.9081 - val_f1_score: 0.6500 - lr: 9.0000e-04\n",
      "Epoch 16/100\n",
      "58/58 [==============================] - 11s 193ms/step - loss: 0.2202 - binary_accuracy: 0.9061 - auc: 0.9477 - f1_score: 0.7415 - val_loss: 0.3069 - val_binary_accuracy: 0.8769 - val_auc: 0.9111 - val_f1_score: 0.6225 - lr: 9.0000e-04\n",
      "Epoch 17/100\n",
      "58/58 [==============================] - 11s 196ms/step - loss: 0.2132 - binary_accuracy: 0.9088 - auc: 0.9508 - f1_score: 0.7439 - val_loss: 0.2918 - val_binary_accuracy: 0.8812 - val_auc: 0.9153 - val_f1_score: 0.6497 - lr: 9.0000e-04\n",
      "Epoch 18/100\n",
      "58/58 [==============================] - 11s 196ms/step - loss: 0.2124 - binary_accuracy: 0.9118 - auc: 0.9529 - f1_score: 0.7554 - val_loss: 0.2929 - val_binary_accuracy: 0.8790 - val_auc: 0.9202 - val_f1_score: 0.6456 - lr: 8.1000e-04\n",
      "Epoch 19/100\n",
      "58/58 [==============================] - 11s 194ms/step - loss: 0.2062 - binary_accuracy: 0.9148 - auc: 0.9560 - f1_score: 0.7663 - val_loss: 0.2877 - val_binary_accuracy: 0.8769 - val_auc: 0.9207 - val_f1_score: 0.6460 - lr: 8.1000e-04\n",
      "Epoch 20/100\n",
      "58/58 [==============================] - 11s 197ms/step - loss: 0.2039 - binary_accuracy: 0.9137 - auc: 0.9559 - f1_score: 0.7605 - val_loss: 0.2977 - val_binary_accuracy: 0.8790 - val_auc: 0.9122 - val_f1_score: 0.6667 - lr: 8.1000e-04\n",
      "Epoch 21/100\n",
      "58/58 [==============================] - 11s 194ms/step - loss: 0.2016 - binary_accuracy: 0.9132 - auc: 0.9575 - f1_score: 0.7656 - val_loss: 0.2964 - val_binary_accuracy: 0.8790 - val_auc: 0.9124 - val_f1_score: 0.6456 - lr: 8.1000e-04\n",
      "Epoch 22/100\n",
      "58/58 [==============================] - 11s 196ms/step - loss: 0.1956 - binary_accuracy: 0.9177 - auc: 0.9600 - f1_score: 0.7695 - val_loss: 0.3115 - val_binary_accuracy: 0.8769 - val_auc: 0.9063 - val_f1_score: 0.6225 - lr: 8.1000e-04\n",
      "Epoch 23/100\n",
      "58/58 [==============================] - 11s 194ms/step - loss: 0.1986 - binary_accuracy: 0.9172 - auc: 0.9586 - f1_score: 0.7738 - val_loss: 0.3126 - val_binary_accuracy: 0.8769 - val_auc: 0.9046 - val_f1_score: 0.6545 - lr: 8.1000e-04\n",
      "Epoch 24/100\n",
      "58/58 [==============================] - 11s 195ms/step - loss: 0.1899 - binary_accuracy: 0.9223 - auc: 0.9623 - f1_score: 0.7892 - val_loss: 0.3229 - val_binary_accuracy: 0.8790 - val_auc: 0.9056 - val_f1_score: 0.6267 - lr: 8.1000e-04\n"
     ]
    }
   ],
   "source": [
    "result = rnn_model.train(X_train_input, X_train_input_f, X_train_input_m,\n",
    "                y_train, X_val_input, X_val_input_f, X_val_input_m, y_val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3e59e185-f4d0-4b4e-b642-eec8489675e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x26a0bf2b970>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(rnn_model.result.history['loss'], label='train')\n",
    "plt.plot(rnn_model.result.history['val_loss'], label='val')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a636dab2-5e44-4228-bf78-4c137b2dc30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 49ms/step - loss: 0.3503 - binary_accuracy: 0.8728 - auc: 0.8926 - f1_score: 0.6467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3502943515777588,\n",
       " 0.8728448152542114,\n",
       " 0.8926301598548889,\n",
       " array([0.6467066], dtype=float32)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model.evaluate([X_test_input, X_test_input_f, X_test_input_m], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "68ca2e05-a423-4482-a4db-694dc79f449d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 48ms/step - loss: 0.3503 - binary_accuracy: 0.8728 - auc: 0.8926 - f1_score: 0.6467\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, auc, f1 = rnn_model.evaluate([X_test_input, X_test_input_f, X_test_input_m], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "00e479f1-0876-4c28-ab40-6a205edc635d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6467066"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d65e0-3c9a-4070-8e56-53b3632d5e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn_model.result.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e68c44eb-20db-4edc-8c8a-cd89f7b8c0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn import clone\n",
    "def base_model_crossvalidation(ml_model,df, X_columns, y_columns, n_folds=5, verbose=False):\n",
    "    \"\"\"\n",
    "    Machine learning model training and validation in a cross-validation loop.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ml_model: sklearn model object\n",
    "        The machine learning model to train.\n",
    "    df: pd.DataFrame\n",
    "        Data set with SMILES and their associated activity labels.\n",
    "    n_folds: int, optional\n",
    "        Number of folds for cross-validation.\n",
    "    verbose: bool, optional\n",
    "        Performance measures are printed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    # Shuffle the indices for the k-fold cross-validation\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
    "\n",
    "    # Results for each of the cross-validation folds\n",
    "    acc_per_fold = []\n",
    "    f1_per_fold = []\n",
    "    auc_per_fold = []\n",
    "\n",
    "    # Loop over the folds\n",
    "    for train_index, test_index in tqdm(kf.split(df)):\n",
    "        # clone model -- we want a fresh copy per fold!\n",
    "        fold_model = clone(ml_model)\n",
    "        # Training\n",
    "\n",
    "        # Convert the fingerprint and the label to a list\n",
    "        train_x = np.vstack(df[X_columns].iloc[train_index])\n",
    "        train_y = np.vstack(df[y_columns].iloc[train_index])\n",
    "\n",
    "\n",
    "        # Fit the model\n",
    "        fold_model.fit(train_x, train_y)\n",
    "\n",
    "        # Testing\n",
    "\n",
    "        # Convert the fingerprint and the label to a list\n",
    "        test_x = np.vstack(df[X_columns].iloc[test_index])\n",
    "        test_y = np.vstack(df[y_columns].iloc[test_index])\n",
    "\n",
    "        # Performance for each fold\n",
    "        accuracy, auc, f1 = utils.model_performance(fold_model, test_x, test_y, verbose)\n",
    "\n",
    "        # Save results\n",
    "        acc_per_fold.append(accuracy)\n",
    "        auc_per_fold.append(auc)\n",
    "        f1_per_fold.append(f1)\n",
    "\n",
    "    # Print statistics of results\n",
    "    print(\n",
    "        f\"ACC:\\t {np.mean(acc_per_fold):.2f}\"\n",
    "        f\" Â± {np.std(acc_per_fold):.2f} \\n\"\n",
    "        f\"AUC:\\t {np.mean(auc_per_fold):.2f}\"\n",
    "        f\" Â± {np.std(auc_per_fold):.2f} \\n\"\n",
    "        f\"F1:\\t {np.mean(f1_per_fold):.2f}\"\n",
    "        f\" Â± {np.std(f1_per_fold):.2f} \\n\"\n",
    "    )\n",
    "    results_dict = {\n",
    "        'ACC': {\n",
    "            'mean': f\"{np.mean(acc_per_fold):.3g}\",\n",
    "            'std': f\"{np.std(acc_per_fold):.3g}\"\n",
    "        },\n",
    "        'AUC': {\n",
    "            'mean': f\"{np.mean(auc_per_fold):.3g}\",\n",
    "            'std': f\"{np.std(auc_per_fold):.3g}\"\n",
    "        },\n",
    "        'F1': {\n",
    "            'mean': f\"{np.mean(f1_per_fold):.3g}\",\n",
    "            'std': f\"{np.std(f1_per_fold):.3g}\"\n",
    "        }\n",
    "    }\n",
    "    return results_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5642abb0-5878-49c1-8175-deb3237c262b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:20,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC:\t 0.87 Â± 0.01 \n",
      "AUC:\t 0.90 Â± 0.01 \n",
      "F1:\t 0.61 Â± 0.02 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ACC': {'mean': '0.866', 'std': '0.0111'},\n",
       " 'AUC': {'mean': '0.903', 'std': '0.0125'},\n",
       " 'F1': {'mean': '0.61', 'std': '0.0201'}}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {\n",
    "    \"n_estimators\": 50,  # number of trees to grows\n",
    "    \"criterion\": \"entropy\",  # loss function to be optimized for a split\n",
    "}\n",
    "model_RF = RandomForestClassifier(**param)\n",
    "\n",
    "base_line_cv = base_model_crossvalidation(model_RF, df, X_columns='finger print', y_columns='active')\n",
    "base_line_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "550c9bc0-a2cb-4812-b2a5-3cadc64a685f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:06,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC:\t 0.85 Â± 0.01 \n",
      "AUC:\t 0.88 Â± 0.01 \n",
      "F1:\t 0.58 Â± 0.02 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Specify model\n",
    "model_lr = LogisticRegression(max_iter=2000)\n",
    "\n",
    "base_line_cv = base_model_crossvalidation(model_lr, df, X_columns='finger print', y_columns='active')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1a6962f5-e06e-4d4b-a49f-0f2616c00a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_indices = [26, 27, 48, 55, 72, 124, 125, 126, 127, 129, 132, 133, 135, 136, 137, 138, 142, 143,\n",
    "         144, 145, 147, 148, 150, 151, 153, 154, 155, 156, 158, 160, 163, 164, 165, 167, 168, 169,\n",
    "         170, 171, 172, 173, 174, 176, 177, 179, 180, 181, 185, 186, 188, 190, 192, 193, 194, 196,\n",
    "         197, 199, 200, 201, 203, 204, 206, 207, 209, 210, 211, 220, 251, 260, 261, 263, 265, 270,\n",
    "         271, 272, 295, 316, 343, 344, 349, 350, 354, 358, 386, 387, 399, 409, 410, 416, 417, 418,\n",
    "         423, 426, 428, 429, 431, 433, 434, 441, 445, 452, 455, 459, 464, 468, 469, 470, 471, 472,\n",
    "         473, 474, 488, 489, 491, 492, 493, 494, 495, 496, 514, 527, 600, 602, 603, 612, 613, 616,\n",
    "         617, 618, 623, 638] \n",
    "\n",
    "# selected_feature_indices = [ 12, 203, 298, 312, 316, 340, 354, 358, 387, 388, 444, 455, 503,\n",
    "#        514, 523, 527, 556, 565, 572, 578]\n",
    "\n",
    "\n",
    "\n",
    "j = X_train.shape[1]- len(df['encoding'].iloc[0])\n",
    "k = mordred_array_without_nan.shape[1]\n",
    "\n",
    "X_train_input, X_train_input_f, X_train_input_m, \\\n",
    "X_val_input, X_val_input_f, X_val_input_m, \\\n",
    "X_test_input, X_test_input_f, X_test_input_m = prepare_RNN_data(\n",
    "    X_train, X_val, X_test, j, k, selected_feature_indices)\n",
    "\n",
    "\n",
    "def RNN_model_crossvalidation(df, n_folds=5, verbose=False):\n",
    "    \"\"\"\n",
    "    Machine learning model training and validation in a cross-validation loop.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ml_model: sklearn model object\n",
    "        The machine learning model to train.\n",
    "    df: pd.DataFrame\n",
    "        Data set with SMILES and their associated activity labels.\n",
    "    n_folds: int, optional\n",
    "        Number of folds for cross-validation.\n",
    "    verbose: bool, optional\n",
    "        Performance measures are printed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    # Shuffle the indices for the k-fold cross-validation\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
    "\n",
    "    # Results for each of the cross-validation folds\n",
    "    acc_per_fold = []\n",
    "    f1_per_fold = []\n",
    "    auc_per_fold = []\n",
    "\n",
    "    # Loop over the folds\n",
    "    for train_index, test_index in tqdm(kf.split(df)):\n",
    "        # clone model -- we want a fresh copy per fold!\n",
    "        rnn_model = RNNModel(lstm_config, input_shapes)\n",
    "        # Training\n",
    "\n",
    "        X_e = np.vstack(df['encoding'])\n",
    "        X_= np.vstack(df['finger print'])\n",
    "        # X_m = np.vstack(df['other desc'])\n",
    "        X_m = mordred_array_without_nan\n",
    "        X = np.concatenate([X_e, X_,X_m],axis=1)\n",
    "\n",
    "        X_train = X[train_index]\n",
    "        X_test = X[test_index]\n",
    "        y = np.vstack(df['active'])\n",
    "        y_train = y[train_index]\n",
    "        y_test = y[test_index]\n",
    "        \n",
    "        \n",
    "        X_train_input, X_train_input_f, X_train_input_m, \\\n",
    "        _, _, _, \\\n",
    "        X_test_input, X_test_input_f, X_test_input_m = prepare_RNN_data(\n",
    "            X_train, X_val, X_test, j, k, selected_feature_indices)\n",
    "\n",
    "        # Fit the model\n",
    "        result = rnn_model.train(X_train_input, X_train_input_f, X_train_input_m,\n",
    "                y_train, X_test_input, X_test_input_f, X_test_input_m, y_test, verbose=1)\n",
    "\n",
    "        # Performance for each fold\n",
    "        loss, accuracy, auc, f1 = rnn_model.evaluate([X_test_input, X_test_input_f, X_test_input_m], y_test)\n",
    "        f1 = f1[0]\n",
    "\n",
    "        # Save results\n",
    "        acc_per_fold.append(accuracy)\n",
    "        auc_per_fold.append(auc)\n",
    "        f1_per_fold.append(f1)\n",
    "\n",
    "    # Print statistics of results\n",
    "    print(\n",
    "        f\"ACC:\\t {np.mean(acc_per_fold):.2f}\"\n",
    "        f\" Â± {np.std(acc_per_fold):.2f} \\n\"\n",
    "        f\"AUC:\\t {np.mean(auc_per_fold):.2f}\"\n",
    "        f\" Â± {np.std(auc_per_fold):.2f} \\n\"\n",
    "        f\"F1:\\t {np.mean(f1_per_fold):.2f}\"\n",
    "        f\" Â± {np.std(f1_per_fold):.2f} \\n\"\n",
    "    )\n",
    "    results_dict = {\n",
    "        'ACC': {\n",
    "            'mean': f\"{np.mean(acc_per_fold):.3g}\",\n",
    "            'std': f\"{np.std(acc_per_fold):.3g}\"\n",
    "        },\n",
    "        'AUC': {\n",
    "            'mean': f\"{np.mean(auc_per_fold):.3g}\",\n",
    "            'std': f\"{np.std(auc_per_fold):.3g}\"\n",
    "        },\n",
    "        'F1': {\n",
    "            'mean': f\"{np.mean(f1_per_fold):.3g}\",\n",
    "            'std': f\"{np.std(f1_per_fold):.3g}\"\n",
    "        }\n",
    "    }\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0d2aa939-3b13-4cd5-ac00-e41c22d4fbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "58/58 [==============================] - 45s 350ms/step - loss: 0.4903 - binary_accuracy: 0.7853 - auc: 0.7012 - f1_score: 0.2790 - val_loss: 0.4132 - val_binary_accuracy: 0.8166 - val_auc: 0.7988 - val_f1_score: 0.3145 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 14s 236ms/step - loss: 0.3836 - binary_accuracy: 0.8242 - auc: 0.8217 - f1_score: 0.4360 - val_loss: 0.3609 - val_binary_accuracy: 0.8436 - val_auc: 0.8548 - val_f1_score: 0.5367 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 14s 235ms/step - loss: 0.3445 - binary_accuracy: 0.8498 - auc: 0.8587 - f1_score: 0.5331 - val_loss: 0.3637 - val_binary_accuracy: 0.8403 - val_auc: 0.8597 - val_f1_score: 0.4478 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 14s 236ms/step - loss: 0.3212 - binary_accuracy: 0.8560 - auc: 0.8827 - f1_score: 0.5630 - val_loss: 0.3364 - val_binary_accuracy: 0.8522 - val_auc: 0.8773 - val_f1_score: 0.5651 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 14s 236ms/step - loss: 0.3061 - binary_accuracy: 0.8614 - auc: 0.8963 - f1_score: 0.5972 - val_loss: 0.3441 - val_binary_accuracy: 0.8522 - val_auc: 0.8786 - val_f1_score: 0.5292 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 14s 235ms/step - loss: 0.2931 - binary_accuracy: 0.8746 - auc: 0.9031 - f1_score: 0.6301 - val_loss: 0.3508 - val_binary_accuracy: 0.8554 - val_auc: 0.8804 - val_f1_score: 0.5347 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 14s 237ms/step - loss: 0.2822 - binary_accuracy: 0.8768 - auc: 0.9105 - f1_score: 0.6466 - val_loss: 0.3437 - val_binary_accuracy: 0.8554 - val_auc: 0.8872 - val_f1_score: 0.5379 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 14s 239ms/step - loss: 0.2723 - binary_accuracy: 0.8881 - auc: 0.9174 - f1_score: 0.6785 - val_loss: 0.3285 - val_binary_accuracy: 0.8662 - val_auc: 0.8886 - val_f1_score: 0.6026 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 14s 240ms/step - loss: 0.2566 - binary_accuracy: 0.8919 - auc: 0.9283 - f1_score: 0.6870 - val_loss: 0.3213 - val_binary_accuracy: 0.8684 - val_auc: 0.8950 - val_f1_score: 0.6514 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - 14s 240ms/step - loss: 0.2590 - binary_accuracy: 0.8886 - auc: 0.9304 - f1_score: 0.6830 - val_loss: 0.3599 - val_binary_accuracy: 0.8544 - val_auc: 0.8855 - val_f1_score: 0.5296 - lr: 9.0000e-04\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - 14s 236ms/step - loss: 0.2460 - binary_accuracy: 0.8943 - auc: 0.9346 - f1_score: 0.7003 - val_loss: 0.3367 - val_binary_accuracy: 0.8662 - val_auc: 0.8977 - val_f1_score: 0.6125 - lr: 9.0000e-04\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - 13s 233ms/step - loss: 0.2397 - binary_accuracy: 0.9008 - auc: 0.9390 - f1_score: 0.7199 - val_loss: 0.3429 - val_binary_accuracy: 0.8652 - val_auc: 0.8899 - val_f1_score: 0.6032 - lr: 9.0000e-04\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - 14s 234ms/step - loss: 0.2403 - binary_accuracy: 0.8999 - auc: 0.9366 - f1_score: 0.7148 - val_loss: 0.3364 - val_binary_accuracy: 0.8662 - val_auc: 0.8930 - val_f1_score: 0.6026 - lr: 9.0000e-04\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - 14s 236ms/step - loss: 0.2247 - binary_accuracy: 0.9051 - auc: 0.9467 - f1_score: 0.7361 - val_loss: 0.3689 - val_binary_accuracy: 0.8673 - val_auc: 0.8890 - val_f1_score: 0.5802 - lr: 9.0000e-04\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - 14s 234ms/step - loss: 0.2307 - binary_accuracy: 0.9024 - auc: 0.9429 - f1_score: 0.7228 - val_loss: 0.3307 - val_binary_accuracy: 0.8716 - val_auc: 0.8951 - val_f1_score: 0.6448 - lr: 9.0000e-04\n",
      "Epoch 16/100\n",
      "58/58 [==============================] - 14s 237ms/step - loss: 0.2312 - binary_accuracy: 0.9048 - auc: 0.9428 - f1_score: 0.7372 - val_loss: 0.3595 - val_binary_accuracy: 0.8619 - val_auc: 0.8938 - val_f1_score: 0.5616 - lr: 9.0000e-04\n",
      "29/29 [==============================] - 1s 50ms/step - loss: 0.3367 - binary_accuracy: 0.8662 - auc: 0.8977 - f1_score: 0.6125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [04:16, 256.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "58/58 [==============================] - 45s 343ms/step - loss: 0.4587 - binary_accuracy: 0.7907 - auc: 0.7158 - f1_score: 0.2286 - val_loss: 0.3631 - val_binary_accuracy: 0.8393 - val_auc: 0.8398 - val_f1_score: 0.2938 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 14s 234ms/step - loss: 0.3756 - binary_accuracy: 0.8296 - auc: 0.8345 - f1_score: 0.4598 - val_loss: 0.3310 - val_binary_accuracy: 0.8641 - val_auc: 0.8709 - val_f1_score: 0.5500 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 14s 234ms/step - loss: 0.3392 - binary_accuracy: 0.8479 - auc: 0.8720 - f1_score: 0.5559 - val_loss: 0.3288 - val_binary_accuracy: 0.8576 - val_auc: 0.8820 - val_f1_score: 0.6229 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 13s 229ms/step - loss: 0.3157 - binary_accuracy: 0.8627 - auc: 0.8901 - f1_score: 0.6164 - val_loss: 0.3191 - val_binary_accuracy: 0.8695 - val_auc: 0.8807 - val_f1_score: 0.5255 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 13s 228ms/step - loss: 0.3000 - binary_accuracy: 0.8759 - auc: 0.9012 - f1_score: 0.6603 - val_loss: 0.3094 - val_binary_accuracy: 0.8641 - val_auc: 0.8893 - val_f1_score: 0.5191 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 13s 227ms/step - loss: 0.2926 - binary_accuracy: 0.8751 - auc: 0.9069 - f1_score: 0.6506 - val_loss: 0.3060 - val_binary_accuracy: 0.8695 - val_auc: 0.8914 - val_f1_score: 0.6254 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 13s 229ms/step - loss: 0.2751 - binary_accuracy: 0.8843 - auc: 0.9210 - f1_score: 0.6848 - val_loss: 0.2927 - val_binary_accuracy: 0.8792 - val_auc: 0.8990 - val_f1_score: 0.6164 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 13s 230ms/step - loss: 0.2633 - binary_accuracy: 0.8881 - auc: 0.9287 - f1_score: 0.6946 - val_loss: 0.3115 - val_binary_accuracy: 0.8554 - val_auc: 0.9002 - val_f1_score: 0.6298 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 13s 230ms/step - loss: 0.2683 - binary_accuracy: 0.8835 - auc: 0.9256 - f1_score: 0.6892 - val_loss: 0.3037 - val_binary_accuracy: 0.8803 - val_auc: 0.8887 - val_f1_score: 0.6050 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - 13s 228ms/step - loss: 0.2474 - binary_accuracy: 0.8975 - auc: 0.9375 - f1_score: 0.7230 - val_loss: 0.3033 - val_binary_accuracy: 0.8770 - val_auc: 0.8931 - val_f1_score: 0.6122 - lr: 9.0000e-04\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - 13s 229ms/step - loss: 0.2533 - binary_accuracy: 0.8943 - auc: 0.9319 - f1_score: 0.7139 - val_loss: 0.2931 - val_binary_accuracy: 0.8738 - val_auc: 0.9016 - val_f1_score: 0.6378 - lr: 9.0000e-04\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - 13s 231ms/step - loss: 0.2353 - binary_accuracy: 0.8981 - auc: 0.9441 - f1_score: 0.7292 - val_loss: 0.2878 - val_binary_accuracy: 0.8835 - val_auc: 0.9045 - val_f1_score: 0.6424 - lr: 9.0000e-04\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - 13s 229ms/step - loss: 0.2350 - binary_accuracy: 0.8991 - auc: 0.9444 - f1_score: 0.7290 - val_loss: 0.2911 - val_binary_accuracy: 0.8878 - val_auc: 0.9036 - val_f1_score: 0.6579 - lr: 9.0000e-04\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - 13s 229ms/step - loss: 0.2399 - binary_accuracy: 0.8946 - auc: 0.9421 - f1_score: 0.7123 - val_loss: 0.2970 - val_binary_accuracy: 0.8803 - val_auc: 0.9048 - val_f1_score: 0.5874 - lr: 9.0000e-04\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - 13s 227ms/step - loss: 0.2274 - binary_accuracy: 0.9016 - auc: 0.9469 - f1_score: 0.7326 - val_loss: 0.2976 - val_binary_accuracy: 0.8900 - val_auc: 0.8987 - val_f1_score: 0.6383 - lr: 9.0000e-04\n",
      "Epoch 16/100\n",
      "58/58 [==============================] - 13s 232ms/step - loss: 0.2165 - binary_accuracy: 0.9083 - auc: 0.9538 - f1_score: 0.7561 - val_loss: 0.2925 - val_binary_accuracy: 0.8738 - val_auc: 0.9105 - val_f1_score: 0.6609 - lr: 9.0000e-04\n",
      "Epoch 17/100\n",
      "58/58 [==============================] - 13s 228ms/step - loss: 0.2140 - binary_accuracy: 0.9094 - auc: 0.9551 - f1_score: 0.7586 - val_loss: 0.3076 - val_binary_accuracy: 0.8846 - val_auc: 0.8948 - val_f1_score: 0.6165 - lr: 9.0000e-04\n",
      "Epoch 18/100\n",
      "58/58 [==============================] - 14s 234ms/step - loss: 0.2213 - binary_accuracy: 0.9051 - auc: 0.9498 - f1_score: 0.7453 - val_loss: 0.2891 - val_binary_accuracy: 0.8910 - val_auc: 0.9055 - val_f1_score: 0.6667 - lr: 8.1000e-04\n",
      "Epoch 19/100\n",
      "58/58 [==============================] - 14s 241ms/step - loss: 0.2160 - binary_accuracy: 0.9040 - auc: 0.9537 - f1_score: 0.7424 - val_loss: 0.2999 - val_binary_accuracy: 0.8857 - val_auc: 0.9026 - val_f1_score: 0.6708 - lr: 8.1000e-04\n",
      "Epoch 20/100\n",
      "58/58 [==============================] - 14s 235ms/step - loss: 0.2068 - binary_accuracy: 0.9118 - auc: 0.9568 - f1_score: 0.7676 - val_loss: 0.3007 - val_binary_accuracy: 0.8889 - val_auc: 0.9007 - val_f1_score: 0.6645 - lr: 8.1000e-04\n",
      "Epoch 21/100\n",
      "58/58 [==============================] - 13s 228ms/step - loss: 0.1984 - binary_accuracy: 0.9164 - auc: 0.9612 - f1_score: 0.7770 - val_loss: 0.2975 - val_binary_accuracy: 0.8803 - val_auc: 0.9095 - val_f1_score: 0.6542 - lr: 8.1000e-04\n",
      "29/29 [==============================] - 1s 50ms/step - loss: 0.2925 - binary_accuracy: 0.8738 - auc: 0.9105 - f1_score: 0.6609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [09:35, 293.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "58/58 [==============================] - 46s 347ms/step - loss: 0.4644 - binary_accuracy: 0.7896 - auc: 0.7040 - f1_score: 0.2412 - val_loss: 0.3887 - val_binary_accuracy: 0.8350 - val_auc: 0.8324 - val_f1_score: 0.4226 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 14s 235ms/step - loss: 0.3650 - binary_accuracy: 0.8347 - auc: 0.8410 - f1_score: 0.4590 - val_loss: 0.3613 - val_binary_accuracy: 0.8468 - val_auc: 0.8583 - val_f1_score: 0.5563 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 13s 230ms/step - loss: 0.3335 - binary_accuracy: 0.8484 - auc: 0.8688 - f1_score: 0.5293 - val_loss: 0.3486 - val_binary_accuracy: 0.8468 - val_auc: 0.8700 - val_f1_score: 0.5506 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 13s 232ms/step - loss: 0.2954 - binary_accuracy: 0.8654 - auc: 0.9041 - f1_score: 0.5817 - val_loss: 0.3637 - val_binary_accuracy: 0.8457 - val_auc: 0.8715 - val_f1_score: 0.5249 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 13s 231ms/step - loss: 0.2910 - binary_accuracy: 0.8673 - auc: 0.9072 - f1_score: 0.6089 - val_loss: 0.3455 - val_binary_accuracy: 0.8447 - val_auc: 0.8770 - val_f1_score: 0.5886 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 13s 229ms/step - loss: 0.2692 - binary_accuracy: 0.8851 - auc: 0.9225 - f1_score: 0.6693 - val_loss: 0.3518 - val_binary_accuracy: 0.8511 - val_auc: 0.8747 - val_f1_score: 0.6080 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 13s 228ms/step - loss: 0.2653 - binary_accuracy: 0.8827 - auc: 0.9246 - f1_score: 0.6641 - val_loss: 0.3605 - val_binary_accuracy: 0.8544 - val_auc: 0.8762 - val_f1_score: 0.6110 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 13s 233ms/step - loss: 0.2710 - binary_accuracy: 0.8778 - auc: 0.9202 - f1_score: 0.6576 - val_loss: 0.3524 - val_binary_accuracy: 0.8511 - val_auc: 0.8721 - val_f1_score: 0.5767 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 13s 229ms/step - loss: 0.2528 - binary_accuracy: 0.8867 - auc: 0.9318 - f1_score: 0.6804 - val_loss: 0.3658 - val_binary_accuracy: 0.8501 - val_auc: 0.8735 - val_f1_score: 0.6085 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - 13s 233ms/step - loss: 0.2351 - binary_accuracy: 0.8970 - auc: 0.9425 - f1_score: 0.7110 - val_loss: 0.3626 - val_binary_accuracy: 0.8468 - val_auc: 0.8728 - val_f1_score: 0.6141 - lr: 9.0000e-04\n",
      "29/29 [==============================] - 1s 49ms/step - loss: 0.3455 - binary_accuracy: 0.8447 - auc: 0.8770 - f1_score: 0.5886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [12:28, 238.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "58/58 [==============================] - 44s 332ms/step - loss: 0.5304 - binary_accuracy: 0.7554 - auc: 0.5917 - f1_score: 0.1134 - val_loss: 0.4307 - val_binary_accuracy: 0.8069 - val_auc: 0.7523 - val_f1_score: 0.0324 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 13s 218ms/step - loss: 0.4238 - binary_accuracy: 0.8131 - auc: 0.7697 - f1_score: 0.2848 - val_loss: 0.3633 - val_binary_accuracy: 0.8436 - val_auc: 0.8454 - val_f1_score: 0.3777 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 12s 208ms/step - loss: 0.3709 - binary_accuracy: 0.8441 - auc: 0.8364 - f1_score: 0.5118 - val_loss: 0.3411 - val_binary_accuracy: 0.8565 - val_auc: 0.8668 - val_f1_score: 0.5611 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 12s 208ms/step - loss: 0.3253 - binary_accuracy: 0.8617 - auc: 0.8831 - f1_score: 0.5945 - val_loss: 0.3389 - val_binary_accuracy: 0.8447 - val_auc: 0.8729 - val_f1_score: 0.5886 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 12s 205ms/step - loss: 0.3162 - binary_accuracy: 0.8665 - auc: 0.8910 - f1_score: 0.6207 - val_loss: 0.3376 - val_binary_accuracy: 0.8587 - val_auc: 0.8757 - val_f1_score: 0.5057 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 12s 207ms/step - loss: 0.2852 - binary_accuracy: 0.8843 - auc: 0.9116 - f1_score: 0.6677 - val_loss: 0.3301 - val_binary_accuracy: 0.8565 - val_auc: 0.8777 - val_f1_score: 0.5233 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 12s 210ms/step - loss: 0.2795 - binary_accuracy: 0.8813 - auc: 0.9167 - f1_score: 0.6646 - val_loss: 0.3401 - val_binary_accuracy: 0.8533 - val_auc: 0.8785 - val_f1_score: 0.5245 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 12s 206ms/step - loss: 0.2681 - binary_accuracy: 0.8846 - auc: 0.9230 - f1_score: 0.6787 - val_loss: 0.3291 - val_binary_accuracy: 0.8522 - val_auc: 0.8827 - val_f1_score: 0.5595 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 12s 207ms/step - loss: 0.2577 - binary_accuracy: 0.8924 - auc: 0.9300 - f1_score: 0.6975 - val_loss: 0.3348 - val_binary_accuracy: 0.8565 - val_auc: 0.8839 - val_f1_score: 0.5857 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - 12s 205ms/step - loss: 0.2514 - binary_accuracy: 0.8951 - auc: 0.9346 - f1_score: 0.7099 - val_loss: 0.3317 - val_binary_accuracy: 0.8619 - val_auc: 0.8854 - val_f1_score: 0.5924 - lr: 9.0000e-04\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - 12s 204ms/step - loss: 0.2411 - binary_accuracy: 0.8991 - auc: 0.9381 - f1_score: 0.7254 - val_loss: 0.3417 - val_binary_accuracy: 0.8673 - val_auc: 0.8838 - val_f1_score: 0.5527 - lr: 9.0000e-04\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - 12s 207ms/step - loss: 0.2458 - binary_accuracy: 0.8900 - auc: 0.9376 - f1_score: 0.6951 - val_loss: 0.3394 - val_binary_accuracy: 0.8576 - val_auc: 0.8871 - val_f1_score: 0.5319 - lr: 9.0000e-04\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - 12s 206ms/step - loss: 0.2345 - binary_accuracy: 0.9056 - auc: 0.9427 - f1_score: 0.7396 - val_loss: 0.3314 - val_binary_accuracy: 0.8522 - val_auc: 0.8892 - val_f1_score: 0.5732 - lr: 9.0000e-04\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - 12s 210ms/step - loss: 0.2177 - binary_accuracy: 0.9088 - auc: 0.9525 - f1_score: 0.7526 - val_loss: 0.3349 - val_binary_accuracy: 0.8511 - val_auc: 0.8872 - val_f1_score: 0.5688 - lr: 9.0000e-04\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - 12s 205ms/step - loss: 0.2231 - binary_accuracy: 0.9070 - auc: 0.9485 - f1_score: 0.7427 - val_loss: 0.3307 - val_binary_accuracy: 0.8501 - val_auc: 0.8925 - val_f1_score: 0.5924 - lr: 9.0000e-04\n",
      "Epoch 16/100\n",
      "58/58 [==============================] - 12s 210ms/step - loss: 0.2246 - binary_accuracy: 0.9013 - auc: 0.9507 - f1_score: 0.7328 - val_loss: 0.3360 - val_binary_accuracy: 0.8490 - val_auc: 0.8911 - val_f1_score: 0.6045 - lr: 9.0000e-04\n",
      "Epoch 17/100\n",
      "58/58 [==============================] - 12s 205ms/step - loss: 0.2057 - binary_accuracy: 0.9115 - auc: 0.9575 - f1_score: 0.7609 - val_loss: 0.3429 - val_binary_accuracy: 0.8565 - val_auc: 0.8865 - val_f1_score: 0.5804 - lr: 9.0000e-04\n",
      "Epoch 18/100\n",
      "58/58 [==============================] - 12s 209ms/step - loss: 0.2002 - binary_accuracy: 0.9161 - auc: 0.9600 - f1_score: 0.7738 - val_loss: 0.3655 - val_binary_accuracy: 0.8544 - val_auc: 0.8772 - val_f1_score: 0.5515 - lr: 8.1000e-04\n",
      "Epoch 19/100\n",
      "58/58 [==============================] - 12s 204ms/step - loss: 0.1997 - binary_accuracy: 0.9129 - auc: 0.9620 - f1_score: 0.7661 - val_loss: 0.3490 - val_binary_accuracy: 0.8554 - val_auc: 0.8821 - val_f1_score: 0.5864 - lr: 8.1000e-04\n",
      "Epoch 20/100\n",
      "58/58 [==============================] - 12s 207ms/step - loss: 0.2015 - binary_accuracy: 0.9140 - auc: 0.9597 - f1_score: 0.7666 - val_loss: 0.3659 - val_binary_accuracy: 0.8598 - val_auc: 0.8779 - val_f1_score: 0.5833 - lr: 8.1000e-04\n",
      "29/29 [==============================] - 1s 46ms/step - loss: 0.3307 - binary_accuracy: 0.8501 - auc: 0.8925 - f1_score: 0.5924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [17:06, 254.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "58/58 [==============================] - 44s 316ms/step - loss: 0.5423 - binary_accuracy: 0.7570 - auc: 0.6200 - f1_score: 0.1977 - val_loss: 0.4216 - val_binary_accuracy: 0.8198 - val_auc: 0.7646 - val_f1_score: 0.3013 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 12s 205ms/step - loss: 0.4132 - binary_accuracy: 0.8193 - auc: 0.7892 - f1_score: 0.4312 - val_loss: 0.3545 - val_binary_accuracy: 0.8587 - val_auc: 0.8437 - val_f1_score: 0.5529 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 12s 206ms/step - loss: 0.3602 - binary_accuracy: 0.8457 - auc: 0.8526 - f1_score: 0.5496 - val_loss: 0.3398 - val_binary_accuracy: 0.8565 - val_auc: 0.8660 - val_f1_score: 0.5552 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 12s 206ms/step - loss: 0.3365 - binary_accuracy: 0.8571 - auc: 0.8727 - f1_score: 0.5942 - val_loss: 0.3512 - val_binary_accuracy: 0.8533 - val_auc: 0.8752 - val_f1_score: 0.4516 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 12s 204ms/step - loss: 0.3101 - binary_accuracy: 0.8724 - auc: 0.8923 - f1_score: 0.6381 - val_loss: 0.3247 - val_binary_accuracy: 0.8587 - val_auc: 0.8839 - val_f1_score: 0.5559 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 12s 206ms/step - loss: 0.2960 - binary_accuracy: 0.8762 - auc: 0.9034 - f1_score: 0.6483 - val_loss: 0.3211 - val_binary_accuracy: 0.8630 - val_auc: 0.8881 - val_f1_score: 0.6116 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 12s 206ms/step - loss: 0.2839 - binary_accuracy: 0.8794 - auc: 0.9136 - f1_score: 0.6686 - val_loss: 0.3376 - val_binary_accuracy: 0.8576 - val_auc: 0.8943 - val_f1_score: 0.4844 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 12s 206ms/step - loss: 0.2565 - binary_accuracy: 0.8951 - auc: 0.9324 - f1_score: 0.7112 - val_loss: 0.3340 - val_binary_accuracy: 0.8652 - val_auc: 0.8972 - val_f1_score: 0.5455 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 12s 207ms/step - loss: 0.2536 - binary_accuracy: 0.8959 - auc: 0.9334 - f1_score: 0.7149 - val_loss: 0.3222 - val_binary_accuracy: 0.8619 - val_auc: 0.9004 - val_f1_score: 0.5616 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - 12s 205ms/step - loss: 0.2449 - binary_accuracy: 0.9035 - auc: 0.9371 - f1_score: 0.7402 - val_loss: 0.3292 - val_binary_accuracy: 0.8652 - val_auc: 0.9016 - val_f1_score: 0.5583 - lr: 9.0000e-04\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - 12s 203ms/step - loss: 0.2437 - binary_accuracy: 0.8946 - auc: 0.9375 - f1_score: 0.7148 - val_loss: 0.3377 - val_binary_accuracy: 0.8608 - val_auc: 0.8919 - val_f1_score: 0.5798 - lr: 9.0000e-04\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - 12s 211ms/step - loss: 0.2415 - binary_accuracy: 0.9045 - auc: 0.9385 - f1_score: 0.7386 - val_loss: 0.3270 - val_binary_accuracy: 0.8738 - val_auc: 0.8968 - val_f1_score: 0.6034 - lr: 9.0000e-04\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - 12s 205ms/step - loss: 0.2279 - binary_accuracy: 0.9078 - auc: 0.9450 - f1_score: 0.7459 - val_loss: 0.3286 - val_binary_accuracy: 0.8587 - val_auc: 0.8997 - val_f1_score: 0.6113 - lr: 9.0000e-04\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - 12s 207ms/step - loss: 0.2227 - binary_accuracy: 0.9115 - auc: 0.9477 - f1_score: 0.7606 - val_loss: 0.3507 - val_binary_accuracy: 0.8608 - val_auc: 0.8928 - val_f1_score: 0.5409 - lr: 9.0000e-04\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - 12s 204ms/step - loss: 0.2229 - binary_accuracy: 0.9053 - auc: 0.9482 - f1_score: 0.7447 - val_loss: 0.3287 - val_binary_accuracy: 0.8630 - val_auc: 0.8987 - val_f1_score: 0.6068 - lr: 9.0000e-04\n",
      "29/29 [==============================] - 1s 46ms/step - loss: 0.3292 - binary_accuracy: 0.8652 - auc: 0.9016 - f1_score: 0.5583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [20:44, 248.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC:\t 0.86 Â± 0.01 \n",
      "AUC:\t 0.90 Â± 0.01 \n",
      "F1:\t 0.60 Â± 0.03 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ACC': {'mean': '0.86', 'std': '0.0109'},\n",
       " 'AUC': {'mean': '0.896', 'std': '0.0111'},\n",
       " 'F1': {'mean': '0.603', 'std': '0.0339'}}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_model_crossvalidation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5d1e96-4caa-4ab2-b5bd-cd6aea7a8965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "valance",
   "language": "python",
   "name": "valance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
